Note** on Bootstrap Checks

Development vs. production mode
By default, ES binds to loopback addresses for HTTP and transport (internal) communication. 
Fine for development, but it’s useless for production systems. 

To join a cluster, an Elasticsearch node must be reachable via transport communication. 
To join a cluster via a non-loopback address, a node must bind transport to a non-loopback address 
and not be using single-node discovery. 

via http.host
and transport.host

--------
Single-node discovery
We recognize that some users need to bind transport to an external interface for testing their usage of the transport client.
For this situation, we provide the discovery type single-node (configure it by setting discovery.type to single-node);
in this situation, a node will elect itself master and will not join a cluster with any other node.

---------
Forcing the bootstrap checks

If you are running a single node in production, it is possible to evade the bootstrap checks 
(either by not binding transport to an external interface, or by binding transport to an external interface 
and setting the discovery type to single-node). 

To force execution of the bootstrap checks by setting the system property 
es.enforce.bootstrap.checks to true (set this in Setting JVM options, or by adding -Des.enforce.bootstrap.checks=true
 to the environment variable ES_JAVA_OPTS). 

----------
Heap Size check

If a JVM is started with unequal initial and max heap size, it can be prone to pauses as the JVM heap 
is resized during system usage. To avoid these resize pauses, it’s best to start the JVM with the initial heap size 
equal to the maximum heap size. 

Additionally, if bootstrap.memory_lock is enabled, the JVM will lock the initial size of the heap on startup. 
If the initial heap size is not equal to the maximum heap size, after a resize it will not be the case 
that all of the JVM heap is locked in memory. To pass the heap size check, you must configure the heap size.

------------
File descriptor check
File descriptors are a Unix construct for tracking open "files". 
In Unix though, everything is a file. For example, "files" could be a physical file, a virtual file (e.g., /proc/loadavg),
 or network sockets. 

Elasticsearch requires lots of file descriptors (e.g., every shard is composed of multiple segments and other files,
 plus connections to other nodes, etc.). 

---------------
Memory lock check

When the JVM does a major garbage collection it touches every page of the heap. 
If any of those pages are swapped out to disk they will have to be swapped back in to memory. 
That causes lots of disk thrashing that Elasticsearch would much rather use to service requests. 

Thus disallow/minimize swapping. 

However, there are cases where this setting can be passed to Elasticsearch but Elasticsearch is not able to 
lock the heap (e.g., if the elasticsearch user does not have memlock unlimited). 

The memory lock check verifies that if the bootstrap.memory_lock setting is enabled, 
that the JVM was successfully able to lock the heap. 
------------------

Maximum number of threads check

Elasticsearch executes requests by breaking the request down into stages and handing those stages off 
to different thread pool executors. 
There are different thread pool executors for a variety of tasks within Elasticsearch. 

Thus, Elasticsearch needs the ability to create a lot of threads. 
The maximum number of threads check ensures that the Elasticsearch process has the rights to create enough threads 
under normal use. This check is enforced only on Linux. 

If you are on Linux, to pass the maximum number of threads check, you must configure your system to 
allow the Elasticsearch process the ability to create at least 4096 threads. 


This can be done via /etc/security/limits.conf using the nproc setting 
------------------

Max file size check

The segment files that are the components of individual shards and the translog generations 
that are components of the translog can get large (exceeding multiple gigabytes). 

On systems where the max size of files that can be created by the Elasticsearch process is limited, 
this can lead to failed writes. 

Therefore, the safest option here is that the max file size is unlimited and that is what the max file size 
bootstrap check enforces. 
To pass the max file check, you must configure your system to allow the Elasticsearch process 
the ability to write files of unlimited size. 
This can be done via /etc/security/limits.conf using the fsize setting to unlimited 

---------------------

Maximum size virtual memory check

Elasticsearch and Lucene use mmap to great effect to map portions of an index into the Elasticsearch address space.
This keeps certain index data off the JVM heap but in memory for blazing fast access. 

For this to be effective, the Elasticsearch should have unlimited address space. 
The maximum size virtual memory check enforces that the Elasticsearch process has unlimited address space 
and is enforced only on Linux. 
To pass the maximum size virtual memory check, you must configure your system to allow 
the Elasticsearch process the ability to have unlimited address space. 
This can be done via adding <user> - as unlimited to /etc/security/limits.conf. 
This may require you to increase the limits for the root user too.

---------------------

